{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "import gc\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEBACK_DIST=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to downcast data types to 32 bits\n",
    "def downcast(df):\n",
    "    float_cols = [col for col in df if df[col].dtype=='float64']\n",
    "    int_cols = [col for col in df if df[col].dtype=='int64']\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = pickle.load(open('../gen_data/x_train--simple_validation_split.ipynb--.pickle','rb'))\n",
    "y_train_list = pickle.load(open('../gen_data/y_train--simple_validation_split.ipynb--.pickle','rb'))\n",
    "x_test_list = pickle.load(open('../gen_data/test_data_enriched--enrich1.ipynb--.pickle','rb'))\n",
    "\n",
    "items_data = pd.read_csv('../original_data/items.csv')\n",
    "sales = pd.read_csv('../gen_data/train1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_cat = pd.read_csv('../gen_data/train2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "sum=0\n",
    "for month in range(12,33):\n",
    "    print(month)\n",
    "    sum += df_item_cat[df_item_cat.date_block_num==month].shop_id.nunique() * df_item_cat[df_item_cat.date_block_num==month].item_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6186922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(downcast,x_train_list))\n",
    "x_test_list = list(map(downcast,x_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577593, 7)\n",
      "(1609124, 7)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_list[0].shape)\n",
    "print(x_train_list[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate new item variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with sales data, figure out when each item was sold, \n",
    "    #merge this with train/test then transform it to 1/0\n",
    "#fillna with new item?\n",
    "def new_item_var(df):\n",
    "    sales2 = sales.copy()\n",
    "    first_sale_date = sales2.groupby('item_id').date_block_num.min()\n",
    "    sales2['first_sale_date_block'] = sales2.item_id.map(first_sale_date)\n",
    "    sales2 = sales2[['item_id','first_sale_date_block']]\n",
    "    sales2 = sales2.drop_duplicates()\n",
    "    df = df.merge(sales2,on='item_id',how='left')\n",
    "    \n",
    "    #handle nans for test data (which sales2 wont pick up)\n",
    "    df.first_sale_date_block.fillna(999,inplace=True)    \n",
    "    df['new_item'] = (df.first_sale_date_block >= df.date_block_num)*1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list = list(map(new_item_var,x_train_list))\n",
    "x_test_list = list(map(new_item_var,x_test_list))\n",
    "del sales\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to downcast data types to 32 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "    float_cols = [col for col in df if df[col].dtype=='float64']\n",
    "    int_cols = [col for col in df if df[col].dtype=='int64']\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse City data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city = df_item_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_series = pd.Series([re.search('(.*?) ',n).group() for n in df_city.shop_name],index=df_city.index)\n",
    "df_city['city'] = cities_series\n",
    "df_city = df_city[['shop_id','city']].drop_duplicates()\n",
    "df_city = downcast(df_city)\n",
    "\n",
    "x_train_list = list(map(lambda x: x.merge(df_city,on=['shop_id'],how='left'),x_train_list))\n",
    "x_test_list = list(map(lambda x: x.merge(df_city,on=['shop_id'],how='left'),x_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse item category data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_type_series = df_item_cat.item_category_name.map(lambda x: re.split('-',x)[0])\n",
    "df_item_cat['item_type'] = item_type_series\n",
    "\n",
    "item_info_series = df_item_cat.item_category_name.map(lambda x: '-'.join(re.split('-',x)[1:]) if len(re.split('-',x))>1 else 'NAN')\n",
    "df_item_cat['item_info'] = item_info_series\n",
    "\n",
    "df_item_cat = df_item_cat[['item_category_id','item_type','item_info']].drop_duplicates()\n",
    "df_item_cat = downcast(df_item_cat)\n",
    "\n",
    "x_train_list = list(map(lambda x: x.merge(df_item_cat,on=['item_category_id'],how='left'),x_train_list))\n",
    "x_test_list = list(map(lambda x: x.merge(df_item_cat,on=['item_category_id'],how='left'),x_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577593, 12)\n",
      "(1609124, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_list[0].shape)\n",
    "print(x_train_list[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some item_types have unreliable price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_types_with_unreliable_pricing = ['Игры PC ', 'Кино ', 'Игры ', 'Подарки ', 'Служебные']\n",
    "def remove_unreliable_pricing(df):\n",
    "    df.loc[df.item_type.isin(item_types_with_unreliable_pricing),'prop_median_item_price'] = 1\n",
    "    #df.loc[df.item_type.isin(item_types_with_unreliable_pricing),'median_prevmonth_item_price']\n",
    "    #df.loc[df.item_type.isin(item_types_with_unreliable_pricing),'median_prevmonth_shop_item_price']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(remove_unreliable_pricing,x_train_list))\n",
    "x_test_list = list(map(remove_unreliable_pricing,x_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577593, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_name</th>\n",
       "      <th>first_sale_date_block</th>\n",
       "      <th>new_item</th>\n",
       "      <th>city</th>\n",
       "      <th>item_type</th>\n",
       "      <th>item_info</th>\n",
       "      <th>prop_median_item_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>Адыгея ТЦ \"Мега\"</td>\n",
       "      <td>007 Legends [PS3, русская версия]</td>\n",
       "      <td>Игры - PS3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Адыгея</td>\n",
       "      <td>Игры</td>\n",
       "      <td>PS3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>Адыгея ТЦ \"Мега\"</td>\n",
       "      <td>1+1 (BD)</td>\n",
       "      <td>Кино - Blu-Ray</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Адыгея</td>\n",
       "      <td>Кино</td>\n",
       "      <td>Blu-Ray</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>45</td>\n",
       "      <td>Адыгея ТЦ \"Мега\"</td>\n",
       "      <td>1С:Аудиокниги. Мединский В. Мифы о России. О р...</td>\n",
       "      <td>Книги - Аудиокниги 1С</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Адыгея</td>\n",
       "      <td>Книги</td>\n",
       "      <td>Аудиокниги 1С</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>438</td>\n",
       "      <td>45</td>\n",
       "      <td>Адыгея ТЦ \"Мега\"</td>\n",
       "      <td>1С:Аудиотеатр. Лучшие произведения русских пис...</td>\n",
       "      <td>Книги - Аудиокниги 1С</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Адыгея</td>\n",
       "      <td>Книги</td>\n",
       "      <td>Аудиокниги 1С</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>471</td>\n",
       "      <td>49</td>\n",
       "      <td>Адыгея ТЦ \"Мега\"</td>\n",
       "      <td>1С:Бухгалтерия 8 (ред.3.0) как на ладони. Изд ...</td>\n",
       "      <td>Книги - Методические материалы 1С</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Адыгея</td>\n",
       "      <td>Книги</td>\n",
       "      <td>Методические материалы 1С</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_category_id         shop_name  \\\n",
       "0               0        2       27                19  Адыгея ТЦ \"Мега\"   \n",
       "1               0        2       33                37  Адыгея ТЦ \"Мега\"   \n",
       "2               0        2      317                45  Адыгея ТЦ \"Мега\"   \n",
       "3               0        2      438                45  Адыгея ТЦ \"Мега\"   \n",
       "4               0        2      471                49  Адыгея ТЦ \"Мега\"   \n",
       "\n",
       "                                           item_name  \\\n",
       "0                  007 Legends [PS3, русская версия]   \n",
       "1                                           1+1 (BD)   \n",
       "2  1С:Аудиокниги. Мединский В. Мифы о России. О р...   \n",
       "3  1С:Аудиотеатр. Лучшие произведения русских пис...   \n",
       "4  1С:Бухгалтерия 8 (ред.3.0) как на ладони. Изд ...   \n",
       "\n",
       "                  item_category_name  first_sale_date_block  new_item  \\\n",
       "0                         Игры - PS3                      0         1   \n",
       "1                     Кино - Blu-Ray                      0         1   \n",
       "2              Книги - Аудиокниги 1С                      0         1   \n",
       "3              Книги - Аудиокниги 1С                      0         1   \n",
       "4  Книги - Методические материалы 1С                      0         1   \n",
       "\n",
       "      city item_type                   item_info  prop_median_item_price  \n",
       "0  Адыгея      Игры                          PS3                     1.0  \n",
       "1  Адыгея      Кино                      Blu-Ray                     1.0  \n",
       "2  Адыгея     Книги                Аудиокниги 1С                     NaN  \n",
       "3  Адыгея     Книги                Аудиокниги 1С                     NaN  \n",
       "4  Адыгея     Книги    Методические материалы 1С                     NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop name vars\n",
    "def drop_names(df):\n",
    "    return df.drop(['item_name','shop_name','item_category_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(drop_names,x_train_list))\n",
    "x_test_list = list(map(drop_names,x_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that this data is missing a lot of 0 item sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Historical Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train , y_train in zip(x_train_list,y_train_list):\n",
    "    train['item_cnt_month'] = y_train.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df,variables,newvarname):\n",
    "    var_sales = train.groupby(variables,as_index=False).item_cnt_month.sum()\n",
    "    var_sales.columns = variables + [newvarname]\n",
    "    df = df.merge(var_sales,how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_vars_2(train):\n",
    "    train = merge_data(train,['date_block_num','item_id'],'sum_item_sales_back_0')\n",
    "    train = merge_data(train,['date_block_num','shop_id'],'sum_shop_sales_back_0')\n",
    "    train = merge_data(train,['date_block_num','shop_id','item_id'],'item_cnt_month_back_0')\n",
    "    train = merge_data(train,['date_block_num','item_category_id'],'sum_item_cat_sales_back_0')\n",
    "    train = merge_data(train,['date_block_num','shop_id','item_category_id'],'sum_item_cat_shop_sales_back_0')\n",
    "    train = merge_data(train,['date_block_num','city'],'sum_city_back_0')\n",
    "    train = merge_data(train,['date_block_num','item_type'],'sum_itemtype_back_0')\n",
    "    train = merge_data(train,['date_block_num','item_info'],'sum_iteminfo_back_0')\n",
    "    train = merge_data(train,['date_block_num','city','item_id'],'sum_city_item_back_0')\n",
    "    train = merge_data(train,['date_block_num','city','item_category_id'],'sum_city_item_cat_back_0')\n",
    "    train = merge_data(train,['date_block_num','item_type','shop_id'],'sum_itemtype_shop_back_0')\n",
    "    #train = merge_data(train,['date_block_num','item_info','shop_id'],'sum_iteminfo_shop_back_0')\n",
    "    train = merge_data(train,['date_block_num','item_type','city'],'sum_itemtype_city_back_0')\n",
    "    #train = merge_data(train,['date_block_num','item_info','city'],'sum_iteminfo_city_back_0')\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0','sum_city_back_0','sum_itemtype_back_0','sum_iteminfo_back_0','sum_city_item_back_0','sum_city_item_cat_back_0','sum_itemtype_shop_back_0','sum_iteminfo_shop_back_0','sum_itemtype_city_back_0','sum_iteminfo_city_back_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_vars(train):\n",
    "    item_sales = train.groupby(['date_block_num','item_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_sales.columns = ['date_block_num','item_id','sum_item_sales_back_0']\n",
    "    train = train.merge(item_sales,how='left')\n",
    "        #put this in x_val\n",
    "        #then use OOF or permutations to get data for x_train to avoid overfitting\n",
    "            #maybe just do the basic stuff for x_train, worry about overfitting later\n",
    "\n",
    "    shop_sales = train.groupby(['date_block_num','shop_id'],as_index=False).item_cnt_month.sum()\n",
    "    shop_sales.columns = ['date_block_num','shop_id','sum_shop_sales_back_0']\n",
    "    train = train.merge(shop_sales,how='left')\n",
    "\n",
    "    shop_item_sales = train.groupby(['date_block_num','shop_id','item_id'],as_index=False).agg({'item_cnt_month':'sum'})\n",
    "    shop_item_sales.columns = ['date_block_num','shop_id','item_id','item_cnt_month_back_0']\n",
    "    train = train.merge(shop_item_sales,how='left',on=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    item_cat_sales = train.groupby(['date_block_num','item_category_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_cat_sales.columns = ['date_block_num','item_category_id','sum_item_cat_sales_back_0']\n",
    "    train = train.merge(item_cat_sales,how='left')\n",
    "    \n",
    "    item_cat_shop_sales = train.groupby(['date_block_num','shop_id','item_category_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_cat_shop_sales.columns = ['date_block_num','shop_id','item_category_id','sum_item_cat_shop_sales_back_0']\n",
    "    train = train.merge(item_cat_shop_sales,how='left')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list_saved = x_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_list = list(map(create_cat_vars,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(create_cat_vars_2,x_train_list_saved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_list[0].equals(x_train_list_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_list_2[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 0 Entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to include entries where 0 sales were made for item/shop pairs in a month.\n",
    "So this doesnt get out of hand, gonna focus only on all possible item/shop pairs based on sales in that month, \n",
    "this is what the coursera course did, see outside/Programming_assignment_week_4.ipynb for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_zeros(train):\n",
    "    months = range(train.date_block_num.min(),train.date_block_num.max()+1)\n",
    "    to_pandas=[]\n",
    "    print('Computing for month:',end=' ')\n",
    "    for month in months:\n",
    "        print(month,end=', ')\n",
    "        subtrain = train[train.date_block_num==month].copy()\n",
    "        all_shops = subtrain.shop_id.unique()\n",
    "        all_items = subtrain.item_id.unique()\n",
    "\n",
    "        pairs = product(all_shops,all_items)\n",
    "        #print('len(pairs)='+str(len(list(pairs))))\n",
    "        to_pandas.append([(month,x[0],x[1]) for x in pairs])\n",
    "    \n",
    "    train_filled = pd.DataFrame(np.vstack(to_pandas),columns=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    #need to fill name vars\n",
    "    #name_df = train[['shop_id','item_id','item_category_id','item_name','shop_name','item_category_name']]\n",
    "    #train_filled = train_filled.merge(name_df)\n",
    "    \n",
    "    print(train_filled.shape)\n",
    "    train_filled = train_filled.merge(train,how='left',on=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    print(train_filled.shape)\n",
    "    #Re-merge item_category_id and resort columns, this is computationally inefficient but saves time coding\n",
    "    train_filled = train_filled.drop('item_category_id',axis=1).merge(items_data[['item_id','item_category_id']],on='item_id',how='left')\n",
    "    cols = train_filled.columns.tolist()\n",
    "    col_reseq = cols[0:3] + [cols[-1]] + cols[3:-1]\n",
    "    train_filled = train_filled[col_reseq]\n",
    "    #entries where item_cnt_month is supposed to be 0 are now created as NA\n",
    "    train_filled.fillna(0,inplace=True)\n",
    "    \n",
    "    return train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = x_train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d.date_block_num==30].shop_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_list = x_train_list_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1577593, 23)\n",
      "(1609124, 23)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_list[0].shape)\n",
    "print(x_train_list[1].shape)\n",
    "x_train_list_saved = x_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, (10675678, 3)\n",
      "(10675678, 23)\n",
      "Computing for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, (10913850, 3)\n",
      "(10913850, 23)\n"
     ]
    }
   ],
   "source": [
    "x_train_list = list(map(gen_zeros,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10675678, 23)\n",
      "(10913850, 23)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_list[0].shape)\n",
    "print(x_train_list[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lag Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tried to parallelise, but each loop uses a prev bit (its possible tho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from joblib import Parallel , delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def innerfun(dateback,lag_train_filled):\n",
    "        #this line inneficient?\n",
    "        to_shift = lag_train_filled[['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']].copy()\n",
    "        to_shift['date_block_num'] = to_shift.date_block_num + dateback\n",
    "        newcols = ['date_block_num','shop_id','item_id','sum_item_sales_back_'+str(dateback),'sum_shop_sales_back_'+str(dateback),'item_cnt_month_back_'+str(dateback),'sum_item_cat_sales_back_'+str(dateback),'sum_item_cat_shop_sales_back_'+str(dateback)]\n",
    "        to_shift.columns = newcols\n",
    "        #print(newcols)\n",
    "        print(dateback,end=', ')\n",
    "        lag_train_filled = lag_train_filled.merge(to_shift,on=['date_block_num','shop_id','item_id'],how='left').fillna(0)\n",
    "        del to_shift\n",
    "        gc.collect()\n",
    "        return lag_train_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#make this more efficient?\n",
    "def create_lag_train_new(train_filled):\n",
    "    #gonna iterively copy a subset of the data, rename the date block and aome other cols then merge it back in dateback_gen = range(1,13)\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    lag_train_filled = downcast(train_filled)\n",
    "    del train_filled\n",
    "    print('dateback=',end=' ')\n",
    "    gc.collect()\n",
    "    Parallel(n_jobs=-1)(delayed(innerfun)(dateback,lag_train_filled) for dateback in dateback_gen)\n",
    "\n",
    "    \n",
    "    #remove first DATEBACK_DIST many months\n",
    "    lag_train_filled = lag_train_filled[lag_train_filled.date_block_num>=DATEBACK_DIST]\n",
    "    return lag_train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10675678, 23)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newvars = ['sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0','sum_city_back_0','sum_itemtype_back_0','sum_iteminfo_back_0','sum_city_item_back_0','sum_city_item_cat_back_0','sum_itemtype_shop_back_0','sum_iteminfo_shop_back_0','sum_itemtype_city_back_0','sum_iteminfo_city_back_0']\n",
    "newvars = ['sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0','sum_city_back_0','sum_itemtype_back_0','sum_iteminfo_back_0','sum_city_item_back_0','sum_city_item_cat_back_0','sum_itemtype_shop_back_0','sum_itemtype_city_back_0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this more efficient?\n",
    "def create_lag_train(train_filled):\n",
    "    #gonna iterively copy a subset of the data, rename the date block and aome other cols then merge it back in dateback_gen = range(1,13)\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    lag_train_filled = downcast(train_filled)\n",
    "    del train_filled\n",
    "    print('dateback=',end=' ')\n",
    "    gc.collect()\n",
    "    for dateback in dateback_gen: \n",
    "        #this line inneficient?\n",
    "#       to_shift = lag_train_filled[['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']].copy()\n",
    "        to_shift = lag_train_filled[['date_block_num','shop_id','item_id']+newvars].copy()\n",
    "        to_shift['date_block_num'] = to_shift.date_block_num + dateback\n",
    "        newcols = ['date_block_num','shop_id','item_id'] + [x[0:-1]+str(dateback) for x in newvars]\n",
    "        to_shift.columns = newcols\n",
    "        #print(newcols)\n",
    "        print(dateback,end=', ')\n",
    "        lag_train_filled = lag_train_filled.merge(to_shift,on=['date_block_num','shop_id','item_id'],how='left').fillna(0)\n",
    "        del to_shift\n",
    "        gc.collect()\n",
    "    \n",
    "    #remove first DATEBACK_DIST many months\n",
    "    lag_train_filled = lag_train_filled[lag_train_filled.date_block_num>=DATEBACK_DIST]\n",
    "    return lag_train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateback= 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, dateback= 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, Runtime: 1138.486223936081\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#x_train_list = list(map(create_lag_train,x_train_list))\n",
    "x_train_list = list(map(create_lag_train,x_train_list))\n",
    "end = time.time()\n",
    "print('Runtime: '+str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 167)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.97606995900472"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(time.time() - start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 167)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[1][x_train_list[1].date_block_num>=12].shape\n",
    "#This should have 6425094 to mimmick the course script (except this is using all of the shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_test(tup):\n",
    "    train = tup[0]\n",
    "    test = tup[1]\n",
    "    test = downcast(test)\n",
    "    ref_date_block = test.date_block_num.mean()\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    print('Getting information from month:')\n",
    "    for dateback in dateback_gen:\n",
    "        print(str(ref_date_block - dateback),end=', ')\n",
    "        #hist_data = train[train.date_block_num==ref_date_block - dateback][['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']]\n",
    "        hist_data = train[train.date_block_num==ref_date_block - dateback][['date_block_num','shop_id','item_id'] + newvars]\n",
    "        hist_data.date_block_num = ref_date_block\n",
    "        #hist_data.columns = ['date_block_num','shop_id','item_id','sum_item_sales_back_'+str(dateback),'sum_shop_sales_back_'+str(dateback),'item_cnt_month_back_'+str(dateback),'sum_item_cat_sales_back_'+str(dateback),'sum_item_cat_shop_sales_back_'+str(dateback)]\n",
    "        newcols = ['date_block_num','shop_id','item_id'] + [x[0:-1]+str(dateback) for x in newvars]\n",
    "        hist_data.columns = newcols\n",
    "        test = test.merge(hist_data,how='left').fillna(0)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting information from month:\n",
      "32.0, 31.0, 30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, Getting information from month:\n",
      "33.0, 32.0, 31.0, 30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, "
     ]
    }
   ],
   "source": [
    "x_test_list = list(map(create_lag_test,zip(x_train_list,x_test_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 167)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_train(x_train):\n",
    "    return x_train.item_cnt_month.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = list(map(get_y_train,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_train(train):\n",
    "    sum_item_sales_back_0 = train.sum_item_sales_back_0\n",
    "    sum_shop_sales_back_0 = train.sum_shop_sales_back_0\n",
    "    item_cnt_month_back_0 = train.item_cnt_month_back_0\n",
    "\n",
    "    #train = train.drop(['sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','item_cnt_month','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0'],axis=1)\n",
    "    train = train.drop(['item_cnt_month'] + newvars,axis=1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(clear_train,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realign y_train with x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_train_indicies(series):\n",
    "    return series.reset_index().drop('index',axis=1).item_cnt_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = list(map(reset_train_indicies,y_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "saving...\n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "print('saving...')\n",
    "pickle.dump(x_train_list,open('../gen_data/x_train--features1.1.ipynb--.pickle','wb'))\n",
    "print('saving...')\n",
    "pickle.dump(x_test_list,open('../gen_data/x_test--features1.1.ipynb--.pickle','wb'))\n",
    "print('saving...')\n",
    "pickle.dump(y_train_list,open('../gen_data/y_train--features1.1.ipynb--.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_block_num',\n",
       " 'shop_id',\n",
       " 'item_id',\n",
       " 'item_category_id',\n",
       " 'first_sale_date_block',\n",
       " 'new_item',\n",
       " 'city',\n",
       " 'item_type',\n",
       " 'item_info',\n",
       " 'prop_median_item_price',\n",
       " 'sum_item_sales_back_1',\n",
       " 'sum_shop_sales_back_1',\n",
       " 'item_cnt_month_back_1',\n",
       " 'sum_item_cat_sales_back_1',\n",
       " 'sum_item_cat_shop_sales_back_1',\n",
       " 'sum_city_back_1',\n",
       " 'sum_itemtype_back_1',\n",
       " 'sum_iteminfo_back_1',\n",
       " 'sum_city_item_back_1',\n",
       " 'sum_city_item_cat_back_1',\n",
       " 'sum_itemtype_shop_back_1',\n",
       " 'sum_itemtype_city_back_1',\n",
       " 'sum_item_sales_back_2',\n",
       " 'sum_shop_sales_back_2',\n",
       " 'item_cnt_month_back_2',\n",
       " 'sum_item_cat_sales_back_2',\n",
       " 'sum_item_cat_shop_sales_back_2',\n",
       " 'sum_city_back_2',\n",
       " 'sum_itemtype_back_2',\n",
       " 'sum_iteminfo_back_2',\n",
       " 'sum_city_item_back_2',\n",
       " 'sum_city_item_cat_back_2',\n",
       " 'sum_itemtype_shop_back_2',\n",
       " 'sum_itemtype_city_back_2',\n",
       " 'sum_item_sales_back_3',\n",
       " 'sum_shop_sales_back_3',\n",
       " 'item_cnt_month_back_3',\n",
       " 'sum_item_cat_sales_back_3',\n",
       " 'sum_item_cat_shop_sales_back_3',\n",
       " 'sum_city_back_3',\n",
       " 'sum_itemtype_back_3',\n",
       " 'sum_iteminfo_back_3',\n",
       " 'sum_city_item_back_3',\n",
       " 'sum_city_item_cat_back_3',\n",
       " 'sum_itemtype_shop_back_3',\n",
       " 'sum_itemtype_city_back_3',\n",
       " 'sum_item_sales_back_4',\n",
       " 'sum_shop_sales_back_4',\n",
       " 'item_cnt_month_back_4',\n",
       " 'sum_item_cat_sales_back_4',\n",
       " 'sum_item_cat_shop_sales_back_4',\n",
       " 'sum_city_back_4',\n",
       " 'sum_itemtype_back_4',\n",
       " 'sum_iteminfo_back_4',\n",
       " 'sum_city_item_back_4',\n",
       " 'sum_city_item_cat_back_4',\n",
       " 'sum_itemtype_shop_back_4',\n",
       " 'sum_itemtype_city_back_4',\n",
       " 'sum_item_sales_back_5',\n",
       " 'sum_shop_sales_back_5',\n",
       " 'item_cnt_month_back_5',\n",
       " 'sum_item_cat_sales_back_5',\n",
       " 'sum_item_cat_shop_sales_back_5',\n",
       " 'sum_city_back_5',\n",
       " 'sum_itemtype_back_5',\n",
       " 'sum_iteminfo_back_5',\n",
       " 'sum_city_item_back_5',\n",
       " 'sum_city_item_cat_back_5',\n",
       " 'sum_itemtype_shop_back_5',\n",
       " 'sum_itemtype_city_back_5',\n",
       " 'sum_item_sales_back_6',\n",
       " 'sum_shop_sales_back_6',\n",
       " 'item_cnt_month_back_6',\n",
       " 'sum_item_cat_sales_back_6',\n",
       " 'sum_item_cat_shop_sales_back_6',\n",
       " 'sum_city_back_6',\n",
       " 'sum_itemtype_back_6',\n",
       " 'sum_iteminfo_back_6',\n",
       " 'sum_city_item_back_6',\n",
       " 'sum_city_item_cat_back_6',\n",
       " 'sum_itemtype_shop_back_6',\n",
       " 'sum_itemtype_city_back_6',\n",
       " 'sum_item_sales_back_7',\n",
       " 'sum_shop_sales_back_7',\n",
       " 'item_cnt_month_back_7',\n",
       " 'sum_item_cat_sales_back_7',\n",
       " 'sum_item_cat_shop_sales_back_7',\n",
       " 'sum_city_back_7',\n",
       " 'sum_itemtype_back_7',\n",
       " 'sum_iteminfo_back_7',\n",
       " 'sum_city_item_back_7',\n",
       " 'sum_city_item_cat_back_7',\n",
       " 'sum_itemtype_shop_back_7',\n",
       " 'sum_itemtype_city_back_7',\n",
       " 'sum_item_sales_back_8',\n",
       " 'sum_shop_sales_back_8',\n",
       " 'item_cnt_month_back_8',\n",
       " 'sum_item_cat_sales_back_8',\n",
       " 'sum_item_cat_shop_sales_back_8',\n",
       " 'sum_city_back_8',\n",
       " 'sum_itemtype_back_8',\n",
       " 'sum_iteminfo_back_8',\n",
       " 'sum_city_item_back_8',\n",
       " 'sum_city_item_cat_back_8',\n",
       " 'sum_itemtype_shop_back_8',\n",
       " 'sum_itemtype_city_back_8',\n",
       " 'sum_item_sales_back_9',\n",
       " 'sum_shop_sales_back_9',\n",
       " 'item_cnt_month_back_9',\n",
       " 'sum_item_cat_sales_back_9',\n",
       " 'sum_item_cat_shop_sales_back_9',\n",
       " 'sum_city_back_9',\n",
       " 'sum_itemtype_back_9',\n",
       " 'sum_iteminfo_back_9',\n",
       " 'sum_city_item_back_9',\n",
       " 'sum_city_item_cat_back_9',\n",
       " 'sum_itemtype_shop_back_9',\n",
       " 'sum_itemtype_city_back_9',\n",
       " 'sum_item_sales_back_10',\n",
       " 'sum_shop_sales_back_10',\n",
       " 'item_cnt_month_back_10',\n",
       " 'sum_item_cat_sales_back_10',\n",
       " 'sum_item_cat_shop_sales_back_10',\n",
       " 'sum_city_back_10',\n",
       " 'sum_itemtype_back_10',\n",
       " 'sum_iteminfo_back_10',\n",
       " 'sum_city_item_back_10',\n",
       " 'sum_city_item_cat_back_10',\n",
       " 'sum_itemtype_shop_back_10',\n",
       " 'sum_itemtype_city_back_10',\n",
       " 'sum_item_sales_back_11',\n",
       " 'sum_shop_sales_back_11',\n",
       " 'item_cnt_month_back_11',\n",
       " 'sum_item_cat_sales_back_11',\n",
       " 'sum_item_cat_shop_sales_back_11',\n",
       " 'sum_city_back_11',\n",
       " 'sum_itemtype_back_11',\n",
       " 'sum_iteminfo_back_11',\n",
       " 'sum_city_item_back_11',\n",
       " 'sum_city_item_cat_back_11',\n",
       " 'sum_itemtype_shop_back_11',\n",
       " 'sum_itemtype_city_back_11',\n",
       " 'sum_item_sales_back_12',\n",
       " 'sum_shop_sales_back_12',\n",
       " 'item_cnt_month_back_12',\n",
       " 'sum_item_cat_sales_back_12',\n",
       " 'sum_item_cat_shop_sales_back_12',\n",
       " 'sum_city_back_12',\n",
       " 'sum_itemtype_back_12',\n",
       " 'sum_iteminfo_back_12',\n",
       " 'sum_city_item_back_12',\n",
       " 'sum_city_item_cat_back_12',\n",
       " 'sum_itemtype_shop_back_12',\n",
       " 'sum_itemtype_city_back_12']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_order = x_train_list[0].columns.tolist()\n",
    "col_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6186922, 154)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214200, 154)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_list[0] = x_test_list[0][col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_list[1].columns.tolist() == x_train_list[1].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'item_cnt_month'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-8d5e92c0e7aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_cnt_month\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'item_cnt_month'"
     ]
    }
   ],
   "source": [
    "x_train_list[0].item_cnt_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a,b in zip(A,B) if a!=b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_list[0].columns.tolist() == x_train_list[0].columns.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
