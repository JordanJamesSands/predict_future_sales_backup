{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEBACK_DIST=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to downcast data types to 32 bits\n",
    "def downcast(df):\n",
    "    float_cols = [col for col in df if df[col].dtype=='float64']\n",
    "    int_cols = [col for col in df if df[col].dtype=='int64']\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = pickle.load(open('../gen_data/x_train--simple_validation_split.ipynb--.pickle','rb'))\n",
    "y_train_list = pickle.load(open('../gen_data/y_train--simple_validation_split.ipynb--.pickle','rb'))\n",
    "x_test_list = pickle.load(open('../gen_data/test_data_enriched--enrich1.ipynb--.pickle','rb'))\n",
    "\n",
    "items_data = pd.read_csv('../original_data/items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop name vars\n",
    "def drop_names(df):\n",
    "    return df.drop(['item_name','shop_name','item_category_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(drop_names,x_train_list))\n",
    "x_test_list = list(map(drop_names,x_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that this data is missing a lot of 0 item sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Historical Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train , y_train in zip(x_train_list,y_train_list):\n",
    "    train['item_cnt_month'] = y_train.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_vars(train):\n",
    "    item_sales = train.groupby(['date_block_num','item_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_sales.columns = ['date_block_num','item_id','sum_item_sales_back_0']\n",
    "    train = train.merge(item_sales,how='left')\n",
    "        #put this in x_val\n",
    "        #then use OOF or permutations to get data for x_train to avoid overfitting\n",
    "            #maybe just do the basic stuff for x_train, worry about overfitting later\n",
    "\n",
    "    shop_sales = train.groupby(['date_block_num','shop_id'],as_index=False).item_cnt_month.sum()\n",
    "    shop_sales.columns = ['date_block_num','shop_id','sum_shop_sales_back_0']\n",
    "    train = train.merge(shop_sales,how='left')\n",
    "\n",
    "    shop_item_sales = train.groupby(['date_block_num','shop_id','item_id'],as_index=False).agg({'item_cnt_month':'sum'})\n",
    "    shop_item_sales.columns = ['date_block_num','shop_id','item_id','item_cnt_month_back_0']\n",
    "    train = train.merge(shop_item_sales,how='left',on=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    item_cat_sales = train.groupby(['date_block_num','item_category_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_cat_sales.columns = ['date_block_num','item_category_id','sum_item_cat_sales_back_0']\n",
    "    train = train.merge(item_cat_sales,how='left')\n",
    "    \n",
    "    item_cat_shop_sales = train.groupby(['date_block_num','shop_id','item_category_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_cat_shop_sales.columns = ['date_block_num','shop_id','item_category_id','sum_item_cat_shop_sales_back_0']\n",
    "    train = train.merge(item_cat_shop_sales,how='left')\n",
    "    \n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(create_cat_vars,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 0 Entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to include entries where 0 sales were made for item/shop pairs in a month.\n",
    "So this doesnt get out of hand, gonna focus only on all possible item/shop pairs based on sales in that month, \n",
    "this is what the coursera course did, see outside/Programming_assignment_week_4.ipynb for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_zeros(train):\n",
    "    months = range(train.date_block_num.min(),train.date_block_num.max()+1)\n",
    "    to_pandas=[]\n",
    "    print('Computing for month:',end=' ')\n",
    "    for month in months:\n",
    "        print(month,end=', ')\n",
    "        subtrain = train[train.date_block_num==month].copy()\n",
    "        all_shops = subtrain.shop_id.unique()\n",
    "        all_items = subtrain.item_id.unique()\n",
    "\n",
    "        pairs = product(all_shops,all_items)\n",
    "        to_pandas.append([(month,x[0],x[1]) for x in pairs])\n",
    "\n",
    "    train_filled = pd.DataFrame(np.vstack(to_pandas),columns=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    #need to fill name vars\n",
    "    #name_df = train[['shop_id','item_id','item_category_id','item_name','shop_name','item_category_name']]\n",
    "    #train_filled = train_filled.merge(name_df)\n",
    "    \n",
    "    train_filled = train_filled.merge(train,how='left',on=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    #Re-merge item_category_id and resort columns, this is computationally inefficient but saves time coding\n",
    "    train_filled = train_filled.drop('item_category_id',axis=1).merge(items_data[['item_id','item_category_id']],on='item_id',how='left')\n",
    "    cols = train_filled.columns.tolist()\n",
    "    col_reseq = cols[0:3] + [cols[-1]] + cols[3:-1]\n",
    "    train_filled = train_filled[col_reseq]\n",
    "    #entries where item_cnt_month is supposed to be 0 are now created as NA\n",
    "    train_filled.fillna(0,inplace=True)\n",
    "    \n",
    "    return train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, Computing for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, "
     ]
    }
   ],
   "source": [
    "x_train_list = list(map(gen_zeros,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lag Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this more efficient?\n",
    "def create_lag_train(train_filled):\n",
    "    #gonna iterively copy a subset of the data, rename the date block and aome other cols then merge it back in dateback_gen = range(1,13)\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    lag_train_filled = downcast(train_filled)\n",
    "    del train_filled\n",
    "    print('dateback=',end=' ')\n",
    "    gc.collect()\n",
    "    for dateback in dateback_gen: \n",
    "        #this line inneficient?\n",
    "        to_shift = lag_train_filled[['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']].copy()\n",
    "        to_shift['date_block_num'] = to_shift.date_block_num + dateback\n",
    "        newcols = ['date_block_num','shop_id','item_id','sum_item_sales_back_'+str(dateback),'sum_shop_sales_back_'+str(dateback),'item_cnt_month_back_'+str(dateback),'sum_item_cat_sales_back_'+str(dateback),'sum_item_cat_shop_sales_back_'+str(dateback)]\n",
    "        to_shift.columns = newcols\n",
    "        #print(newcols)\n",
    "        print(dateback,end=', ')\n",
    "        lag_train_filled = lag_train_filled.merge(to_shift,on=['date_block_num','shop_id','item_id'],how='left').fillna(0)\n",
    "        del to_shift\n",
    "        gc.collect()\n",
    "    \n",
    "    #remove first DATEBACK_DIST many months\n",
    "    lag_train_filled = lag_train_filled[lag_train_filled.date_block_num>=DATEBACK_DIST]\n",
    "    return lag_train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateback= 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, dateback= 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, "
     ]
    }
   ],
   "source": [
    "x_train_list = list(map(create_lag_train,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 70)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[1][x_train_list[1].date_block_num>=12].shape\n",
    "#This should have 6425094 to mimmick the course script (except this is using all of the shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_test(tup):\n",
    "    train = tup[0]\n",
    "    test = tup[1]\n",
    "    test = downcast(test)\n",
    "    ref_date_block = test.date_block_num.mean()\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    print('Getting information from month:')\n",
    "    for dateback in dateback_gen:\n",
    "        print(str(ref_date_block - dateback),end=', ')\n",
    "        hist_data = train[train.date_block_num==ref_date_block - dateback][['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']]\n",
    "        hist_data.date_block_num = ref_date_block\n",
    "        hist_data.columns = ['date_block_num','shop_id','item_id','sum_item_sales_back_'+str(dateback),'sum_shop_sales_back_'+str(dateback),'item_cnt_month_back_'+str(dateback),'sum_item_cat_sales_back_'+str(dateback),'sum_item_cat_shop_sales_back_'+str(dateback)]\n",
    "        test = test.merge(hist_data,how='left').fillna(0)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting information from month:\n",
      "32.0, 31.0, 30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, Getting information from month:\n",
      "33.0, 32.0, 31.0, 30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, "
     ]
    }
   ],
   "source": [
    "x_test_list = list(map(create_lag_test,zip(x_train_list,x_test_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_train(x_train):\n",
    "    return x_train.item_cnt_month.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = list(map(get_y_train,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_train(train):\n",
    "    sum_item_sales_back_0 = train.sum_item_sales_back_0\n",
    "    sum_shop_sales_back_0 = train.sum_shop_sales_back_0\n",
    "    item_cnt_month_back_0 = train.item_cnt_month_back_0\n",
    "\n",
    "    train = train.drop(['sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','item_cnt_month','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0'],axis=1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(clear_train,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realign y_train with x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_train_indicies(series):\n",
    "    return series.reset_index().drop('index',axis=1).item_cnt_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = list(map(reset_train_indicies,y_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "saving...\n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "print('saving...')\n",
    "pickle.dump(x_train_list,open('../gen_data/x_train--features1.ipynb--.pickle','wb'))\n",
    "print('saving...')\n",
    "pickle.dump(x_test_list,open('../gen_data/x_test--features1.ipynb--.pickle','wb'))\n",
    "print('saving...')\n",
    "pickle.dump(y_train_list,open('../gen_data/y_train--features1.ipynb--.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
