{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATEBACK_DIST=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to downcast data types to 32 bits\n",
    "def downcast(df):\n",
    "    float_cols = [col for col in df if df[col].dtype=='float64']\n",
    "    int_cols = [col for col in df if df[col].dtype=='int64']\n",
    "\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = pickle.load(open('../gen_data/x_train--simple_validation_split.ipynb--.pickle','rb'))\n",
    "y_train_list = pickle.load(open('../gen_data/y_train--simple_validation_split.ipynb--.pickle','rb'))\n",
    "x_test_list = pickle.load(open('../gen_data/test_data_enriched--enrich1.ipynb--.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop name vars\n",
    "def drop_names(df):\n",
    "    return df.drop(['item_name','shop_name','item_category_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(drop_names,x_train_list))\n",
    "x_test_list = list(map(drop_names,x_test_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that this data is missing a lot of 0 item sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Historical Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train , y_train in zip(x_train_list,y_train_list):\n",
    "    train['item_cnt_month'] = y_train.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_vars(train):\n",
    "    item_sales = train.groupby(['date_block_num','item_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_sales.columns = ['date_block_num','item_id','sum_item_sales_back_0']\n",
    "    train = train.merge(item_sales,how='left')\n",
    "        #put this in x_val\n",
    "        #then use OOF or permutations to get data for x_train to avoid overfitting\n",
    "            #maybe just do the basic stuff for x_train, worry about overfitting later\n",
    "\n",
    "    shop_sales = train.groupby(['date_block_num','shop_id'],as_index=False).item_cnt_month.sum()\n",
    "    shop_sales.columns = ['date_block_num','shop_id','sum_shop_sales_back_0']\n",
    "    train = train.merge(shop_sales,how='left')\n",
    "\n",
    "    shop_item_sales = train.groupby(['date_block_num','shop_id','item_id'],as_index=False).agg({'item_cnt_month':'sum'})\n",
    "    shop_item_sales.columns = ['date_block_num','shop_id','item_id','item_cnt_month_back_0']\n",
    "    train = train.merge(shop_item_sales,how='left',on=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    item_cat_sales = train.groupby(['date_block_num','item_category_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_cat_sales.columns = ['date_block_num','item_category_id','sum_item_cat_sales_back_0']\n",
    "    train = train.merge(item_cat_sales,how='left')\n",
    "    \n",
    "    item_cat_shop_sales = train.groupby(['date_block_num','shop_id','item_category_id'],as_index=False).item_cnt_month.sum()\n",
    "    item_cat_shop_sales.columns = ['date_block_num','shop_id','item_category_id','sum_item_cat_shop_sales_back_0']\n",
    "    train = train.merge(item_cat_shop_sales,how='left')\n",
    "    \n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(create_cat_vars,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 0 Entries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to include entries where 0 sales were made for item/shop pairs in a month.\n",
    "So this doesnt get out of hand, gonna focus only on all possible item/shop pairs based on sales in that month, \n",
    "this is what the coursera course did, see outside/Programming_assignment_week_4.ipynb for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_zeros(train):\n",
    "    months = range(train.date_block_num.min(),train.date_block_num.max()+1)\n",
    "    to_pandas=[]\n",
    "    print('Computing for month:',end=' ')\n",
    "    for month in months:\n",
    "        print(month,end=', ')\n",
    "        subtrain = train[train.date_block_num==month].copy()\n",
    "        all_shops = subtrain.shop_id.unique()\n",
    "        all_items = subtrain.item_id.unique()\n",
    "\n",
    "        pairs = product(all_shops,all_items)\n",
    "        to_pandas.append([(month,x[0],x[1]) for x in pairs])\n",
    "\n",
    "    train_filled = pd.DataFrame(np.vstack(to_pandas),columns=['date_block_num','shop_id','item_id'])\n",
    "    \n",
    "    #need to fill name vars\n",
    "    #name_df = train[['shop_id','item_id','item_category_id','item_name','shop_name','item_category_name']]\n",
    "    #train_filled = train_filled.merge(name_df)\n",
    "    \n",
    "    train_filled = train_filled.merge(train,how='left',on=['date_block_num','shop_id','item_id'])\n",
    "   \n",
    "    \n",
    "    \n",
    "    #entries where item_cnt_month is supposed to be 0 are now created as NA\n",
    "    train_filled.fillna(0,inplace=True)\n",
    "    \n",
    "    return train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, Computing for month: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, "
     ]
    }
   ],
   "source": [
    "x_train_list = list(map(gen_zeros,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lag Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make this more efficient?\n",
    "def create_lag_train(train_filled):\n",
    "    #gonna iterively copy a subset of the data, rename the date block and aome other cols then merge it back in dateback_gen = range(1,13)\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    lag_train_filled = downcast(train_filled)\n",
    "    del train_filled\n",
    "    print('dateback=',end=' ')\n",
    "    gc.collect()\n",
    "    for dateback in dateback_gen: \n",
    "        #this line inneficient?\n",
    "        to_shift = lag_train_filled[['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']].copy()\n",
    "        to_shift['date_block_num'] = to_shift.date_block_num + dateback\n",
    "        newcols = ['date_block_num','shop_id','item_id','sum_item_sales_back_'+str(dateback),'sum_shop_sales_back_'+str(dateback),'item_cnt_month_back_'+str(dateback),'sum_item_cat_sales_back_'+str(dateback),'sum_item_cat_shop_sales_back_'+str(dateback)]\n",
    "        to_shift.columns = newcols\n",
    "        #print(newcols)\n",
    "        print(dateback,end=', ')\n",
    "        lag_train_filled = lag_train_filled.merge(to_shift,on=['date_block_num','shop_id','item_id'],how='left').fillna(0)\n",
    "        del to_shift\n",
    "        gc.collect()\n",
    "    \n",
    "    #remove first DATEBACK_DIST many months\n",
    "    lag_train_filled = lag_train_filled[lag_train_filled.date_block_num>=DATEBACK_DIST]\n",
    "    return lag_train_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateback= 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, dateback= 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, "
     ]
    }
   ],
   "source": [
    "x_train_list = list(map(create_lag_train,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6425094, 70)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_list[1][x_train_list[1].date_block_num>=12].shape\n",
    "#This should have 6425094 to mimmick the course script (except this is using all of the shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_test(tup):\n",
    "    train = tup[0]\n",
    "    test = tup[1]\n",
    "    test = downcast(test)\n",
    "    ref_date_block = test.date_block_num.mean()\n",
    "    dateback_gen = range(1,DATEBACK_DIST+1)\n",
    "    print('Getting information from month:')\n",
    "    for dateback in dateback_gen:\n",
    "        print(str(ref_date_block - dateback),end=', ')\n",
    "        hist_data = train[train.date_block_num==ref_date_block - dateback][['date_block_num','shop_id','item_id','sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0']]\n",
    "        hist_data.date_block_num = ref_date_block\n",
    "        hist_data.columns = ['date_block_num','shop_id','item_id','sum_item_sales_back_'+str(dateback),'sum_shop_sales_back_'+str(dateback),'item_cnt_month_back_'+str(dateback),'sum_item_cat_sales_back_'+str(dateback),'sum_item_cat_shop_sales_back_'+str(dateback)]\n",
    "        test = test.merge(hist_data,how='left').fillna(0)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting information from month 32.0\n",
      "Getting information from month 31.0\n",
      "Getting information from month 30.0\n",
      "Getting information from month 29.0\n",
      "Getting information from month 28.0\n",
      "Getting information from month 27.0\n",
      "Getting information from month 26.0\n",
      "Getting information from month 25.0\n",
      "Getting information from month 24.0\n",
      "Getting information from month 23.0\n",
      "Getting information from month 22.0\n",
      "Getting information from month 21.0\n",
      "Getting information from month 33.0\n",
      "Getting information from month 32.0\n",
      "Getting information from month 31.0\n",
      "Getting information from month 30.0\n",
      "Getting information from month 29.0\n",
      "Getting information from month 28.0\n",
      "Getting information from month 27.0\n",
      "Getting information from month 26.0\n",
      "Getting information from month 25.0\n",
      "Getting information from month 24.0\n",
      "Getting information from month 23.0\n",
      "Getting information from month 22.0\n"
     ]
    }
   ],
   "source": [
    "x_test_list = list(map(create_lag_test,zip(x_train_list,x_test_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What if something in train didnt have a item cat id, (or another variable)? would the merge miss it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_train(x_train):\n",
    "    return x_train.item_cnt_month.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = list(map(get_y_train,x_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_train(train):\n",
    "    sum_item_sales_back_0 = train.sum_item_sales_back_0\n",
    "    sum_shop_sales_back_0 = train.sum_shop_sales_back_0\n",
    "    item_cnt_month_back_0 = train.item_cnt_month_back_0\n",
    "\n",
    "    train = train.drop(['sum_item_sales_back_0','sum_shop_sales_back_0','item_cnt_month_back_0','item_cnt_month','sum_item_cat_sales_back_0','sum_item_cat_shop_sales_back_0'],axis=1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = list(map(clear_train,x_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realign y_train with x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_train_indicies(series):\n",
    "    return series.reset_index().drop('index',axis=1).item_cnt_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = list(map(reset_train_indicies,y_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving...\n",
      "saving...\n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "print('saving...')\n",
    "pickle.dump(x_train_list,open('../gen_data/x_train--features1.ipynb--.pickle','wb'))\n",
    "print('saving...')\n",
    "pickle.dump(x_test_list,open('../gen_data/x_test--features1.ipynb--.pickle','wb'))\n",
    "print('saving...')\n",
    "pickle.dump(y_train_list,open('../gen_data/y_train--features1.ipynb--.pickle','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
